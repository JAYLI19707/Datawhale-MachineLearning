{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "增强特征工程版本 - 深度挖掘所有字段！\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"增强特征工程版本 - 深度挖掘所有字段！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "训练集大小: (3429925, 15)\n",
            "测试集大小: (1143309, 14)\n",
            "\n",
            "=== udmap 字段分析 ===\n",
            "训练集 - 空JSON: 3162776, 非空JSON: 0\n",
            "测试集 - 空JSON: 1054255, 非空JSON: 0\n",
            "\n",
            "DID重叠情况:\n",
            "训练集和测试集中重叠的did数量: 192393\n",
            "重叠比例: 0.9324\n",
            "\n",
            "=== 目标变量分布 ===\n",
            "新用户比例: 0.1560\n",
            "新用户数量: 535185\n",
            "老用户数量: 2894740\n",
            "CPU times: total: 11.3 s\n",
            "Wall time: 11.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 1. 数据加载和基础分析\n",
        "train_df = pd.read_csv('./train.csv')\n",
        "test_df = pd.read_csv('./testA_data.csv')\n",
        "submit = test_df[['did']]\n",
        "\n",
        "print(f\"训练集大小: {train_df.shape}\")\n",
        "print(f\"测试集大小: {test_df.shape}\")\n",
        "\n",
        "# 检查udmap字段（验证是否为空）\n",
        "print(f\"\\n=== udmap 字段分析 ===\")\n",
        "def check_udmap(df, name):\n",
        "    empty_count = 0\n",
        "    valid_count = 0\n",
        "    for udmap in df['udmap'].dropna():\n",
        "        try:\n",
        "            parsed = json.loads(udmap)\n",
        "            if len(parsed) == 0:\n",
        "                empty_count += 1\n",
        "            else:\n",
        "                valid_count += 1\n",
        "        except:\n",
        "            pass\n",
        "    print(f\"{name} - 空JSON: {empty_count}, 非空JSON: {valid_count}\")\n",
        "\n",
        "check_udmap(train_df, \"训练集\")\n",
        "check_udmap(test_df, \"测试集\")\n",
        "\n",
        "# 检查did重叠情况\n",
        "train_dids = set(train_df['did'])\n",
        "test_dids = set(test_df['did'])\n",
        "common_dids = train_dids & test_dids\n",
        "print(f\"\\nDID重叠情况:\")\n",
        "print(f\"训练集和测试集中重叠的did数量: {len(common_dids)}\")\n",
        "print(f\"重叠比例: {len(common_dids)/len(test_dids):.4f}\")\n",
        "\n",
        "# 目标变量分布\n",
        "print(f\"\\n=== 目标变量分布 ===\")\n",
        "print(f\"新用户比例: {train_df['is_new_did'].mean():.4f}\")\n",
        "print(f\"新用户数量: {train_df['is_new_did'].sum()}\")\n",
        "print(f\"老用户数量: {(1-train_df['is_new_did']).sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 增强时间特征工程 ===\n",
            "时间特征创建完成！\n",
            "CPU times: total: 859 ms\n",
            "Wall time: 888 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 2. 增强时间特征工程\n",
        "print(\"=== 增强时间特征工程 ===\")\n",
        "\n",
        "for df in [train_df, test_df]:\n",
        "    # 基础时间特征\n",
        "    df['ts'] = pd.to_datetime(df['common_ts'], unit='ms')\n",
        "    df['day'] = df['ts'].dt.day\n",
        "    df['dayofweek'] = df['ts'].dt.dayofweek\n",
        "    df['hour'] = df['ts'].dt.hour\n",
        "    df['minute'] = df['ts'].dt.minute\n",
        "    \n",
        "    # 更细粒度的时间特征\n",
        "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
        "    df['is_workday'] = (df['dayofweek'] < 5).astype(int)\n",
        "    \n",
        "    # 时间段特征\n",
        "    df['time_period'] = pd.cut(df['hour'], \n",
        "                              bins=[0, 6, 12, 18, 24], \n",
        "                              labels=['凌晨', '上午', '下午', '晚上'],\n",
        "                              include_lowest=True)\n",
        "    \n",
        "    # 小时分组（更粗粒度）\n",
        "    df['hour_group'] = pd.cut(df['hour'], \n",
        "                             bins=[0, 8, 16, 24], \n",
        "                             labels=['夜间', '白天', '傍晚'],\n",
        "                             include_lowest=True)\n",
        "    \n",
        "    # 分钟分组\n",
        "    df['minute_group'] = pd.cut(df['minute'], \n",
        "                               bins=[0, 15, 30, 45, 60], \n",
        "                               labels=['0-15', '15-30', '30-45', '45-60'],\n",
        "                               include_lowest=True)\n",
        "\n",
        "print(\"时间特征创建完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 增强RFM特征工程 ===\n",
            "RFM特征数量: 20\n",
            "RFM特征创建完成！\n",
            "CPU times: total: 20.6 s\n",
            "Wall time: 20.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 3. 增强RFM特征工程（仅基于训练集，避免数据泄露）\n",
        "print(\"=== 增强RFM特征工程 ===\")\n",
        "\n",
        "# 基于训练集计算RFM特征\n",
        "max_ts_train = train_df['ts'].max()\n",
        "min_ts_train = train_df['ts'].min()\n",
        "\n",
        "# 基础RFM特征\n",
        "rfm_basic = train_df.groupby('did').agg({\n",
        "    'ts': [\n",
        "        lambda x: (max_ts_train - x.max()).days,  # Recency\n",
        "        lambda x: (x.max() - min_ts_train).days,  # 用户存在时间\n",
        "    ],\n",
        "    'eid': ['count', 'nunique'],  # Frequency: 总行为次数和不同行为数\n",
        "    'mid': ['nunique'],  # Monetary: 不同商品数\n",
        "    'common_ts': ['min', 'max'],  # 首次和末次行为时间\n",
        "    'hour': ['mean', 'std', 'min', 'max'],  # 活跃时间模式\n",
        "    'dayofweek': ['mean', 'std'],  # 活跃日期模式\n",
        "})\n",
        "\n",
        "# 扁平化列名\n",
        "rfm_basic.columns = ['_'.join(col).strip() for col in rfm_basic.columns.values]\n",
        "rfm_basic = rfm_basic.reset_index()\n",
        "\n",
        "# 重命名核心特征\n",
        "rfm_basic.rename(columns={\n",
        "    'ts_<lambda_0>': 'recency_days',\n",
        "    'ts_<lambda_1>': 'user_age_days',\n",
        "    'eid_count': 'frequency_total',\n",
        "    'eid_nunique': 'frequency_unique',\n",
        "    'mid_nunique': 'monetary_unique',\n",
        "    'common_ts_min': 'first_action_ts',\n",
        "    'common_ts_max': 'last_action_ts',\n",
        "    'hour_mean': 'avg_hour',\n",
        "    'hour_std': 'hour_consistency',\n",
        "    'hour_min': 'earliest_hour',\n",
        "    'hour_max': 'latest_hour',\n",
        "    'dayofweek_mean': 'avg_dayofweek',\n",
        "    'dayofweek_std': 'dayofweek_consistency'\n",
        "}, inplace=True)\n",
        "\n",
        "# 计算衍生特征\n",
        "rfm_basic['action_timespan_seconds'] = (rfm_basic['last_action_ts'] - rfm_basic['first_action_ts']) / 1000\n",
        "rfm_basic['action_timespan_days'] = rfm_basic['action_timespan_seconds'] / (24 * 3600)\n",
        "rfm_basic['actions_per_day'] = rfm_basic['frequency_total'] / (rfm_basic['action_timespan_days'] + 1)\n",
        "rfm_basic['unique_action_ratio'] = rfm_basic['frequency_unique'] / rfm_basic['frequency_total']\n",
        "rfm_basic['hour_range'] = rfm_basic['latest_hour'] - rfm_basic['earliest_hour']\n",
        "\n",
        "# 用户活跃度分类\n",
        "rfm_basic['user_activity_level'] = pd.cut(rfm_basic['frequency_total'], \n",
        "                                         bins=[0, 1, 5, 20, float('inf')], \n",
        "                                         labels=['低活跃', '中活跃', '高活跃', '超高活跃'])\n",
        "\n",
        "rfm_basic['user_recency_level'] = pd.cut(rfm_basic['recency_days'], \n",
        "                                        bins=[0, 1, 7, 30, float('inf')], \n",
        "                                        labels=['最近', '一周内', '一月内', '较久前'])\n",
        "\n",
        "print(f\"RFM特征数量: {rfm_basic.shape[1]-1}\")  # 减去did列\n",
        "print(\"RFM特征创建完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 交互特征和聚合统计特征 ===\n",
            "总用户聚合特征数量: 33\n",
            "交互特征和聚合统计特征创建完成！\n",
            "CPU times: total: 1min 34s\n",
            "Wall time: 1min 36s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 4. 交互特征和聚合统计特征（仅基于训练集）\n",
        "print(\"=== 交互特征和聚合统计特征 ===\")\n",
        "\n",
        "# 设备-地域交互特征\n",
        "device_location_stats = train_df.groupby(['device_brand', 'common_province']).size().reset_index(name='device_province_count')\n",
        "train_df = pd.merge(train_df, device_location_stats, on=['device_brand', 'common_province'], how='left')\n",
        "\n",
        "# 渠道-设备交互特征\n",
        "channel_device_stats = train_df.groupby(['channel', 'device_brand']).size().reset_index(name='channel_device_count')\n",
        "train_df = pd.merge(train_df, channel_device_stats, on=['channel', 'device_brand'], how='left')\n",
        "\n",
        "# 运营商-地域交互特征\n",
        "operator_location_stats = train_df.groupby(['operator', 'common_city']).size().reset_index(name='operator_city_count')\n",
        "train_df = pd.merge(train_df, operator_location_stats, on=['operator', 'common_city'], how='left')\n",
        "\n",
        "# 基于用户ID的聚合特征（更多维度）\n",
        "user_advanced_stats = train_df.groupby('did').agg({\n",
        "    'device_brand': lambda x: x.nunique(),\n",
        "    'common_province': lambda x: x.nunique(),\n",
        "    'common_city': lambda x: x.nunique(),\n",
        "    'channel': lambda x: x.nunique(),\n",
        "    'operator': lambda x: x.nunique(),\n",
        "    'os_type': lambda x: x.nunique(),\n",
        "    'appver': lambda x: x.nunique(),\n",
        "    'ntt': ['mean', 'std', 'min', 'max'],\n",
        "    'is_weekend': 'mean',\n",
        "    'time_period': lambda x: x.nunique()\n",
        "}).reset_index()\n",
        "\n",
        "# 扁平化列名\n",
        "user_advanced_stats.columns = ['did'] + ['_'.join(col).strip() if isinstance(col, tuple) else col \n",
        "                                       for col in user_advanced_stats.columns[1:]]\n",
        "\n",
        "# 重命名特征\n",
        "rename_dict = {\n",
        "    'device_brand_<lambda>': 'user_device_diversity',\n",
        "    'common_province_<lambda>': 'user_province_diversity', \n",
        "    'common_city_<lambda>': 'user_city_diversity',\n",
        "    'channel_<lambda>': 'user_channel_diversity',\n",
        "    'operator_<lambda>': 'user_operator_diversity',\n",
        "    'os_type_<lambda>': 'user_os_diversity',\n",
        "    'appver_<lambda>': 'user_appver_diversity',\n",
        "    'time_period_<lambda>': 'user_time_diversity',\n",
        "    'is_weekend_mean': 'weekend_activity_ratio'\n",
        "}\n",
        "\n",
        "for old_name, new_name in rename_dict.items():\n",
        "    if old_name in user_advanced_stats.columns:\n",
        "        user_advanced_stats.rename(columns={old_name: new_name}, inplace=True)\n",
        "\n",
        "# 合并所有RFM和聚合特征\n",
        "all_user_features = pd.merge(rfm_basic, user_advanced_stats, on='did', how='left')\n",
        "\n",
        "print(f\"总用户聚合特征数量: {all_user_features.shape[1]-1}\")\n",
        "print(\"交互特征和聚合统计特征创建完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 特征合并和处理 ===\n",
            "为测试集中的新用户填充特征...\n",
            "特征合并完成！\n",
            "训练集shape: (3429925, 61)\n",
            "测试集shape: (1143309, 60)\n",
            "CPU times: total: 7.14 s\n",
            "Wall time: 7.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 5. 将特征应用到训练集和测试集\n",
        "print(\"=== 特征合并和处理 ===\")\n",
        "\n",
        "# 合并RFM特征到训练集和测试集\n",
        "train_df = pd.merge(train_df, all_user_features, on='did', how='left')\n",
        "\n",
        "# 对测试集进行相同的交互特征处理\n",
        "test_df = pd.merge(test_df, device_location_stats, on=['device_brand', 'common_province'], how='left')\n",
        "test_df = pd.merge(test_df, channel_device_stats, on=['channel', 'device_brand'], how='left') \n",
        "test_df = pd.merge(test_df, operator_location_stats, on=['operator', 'common_city'], how='left')\n",
        "\n",
        "# 对测试集应用用户聚合特征（只有在训练集中出现过的用户才有特征）\n",
        "test_df = pd.merge(test_df, all_user_features, on='did', how='left')\n",
        "\n",
        "# 为新用户填充缺失的聚合特征\n",
        "print(\"为测试集中的新用户填充特征...\")\n",
        "\n",
        "# 获取所有RFM特征列名\n",
        "rfm_feature_cols = [col for col in all_user_features.columns if col != 'did']\n",
        "\n",
        "# 计算训练集特征的统计值用于填充\n",
        "fill_values = {}\n",
        "for col in rfm_feature_cols:\n",
        "    if train_df[col].dtype in ['float64', 'int64']:\n",
        "        fill_values[col] = train_df[col].median()\n",
        "    else:\n",
        "        fill_values[col] = train_df[col].mode()[0] if len(train_df[col].mode()) > 0 else train_df[col].iloc[0]\n",
        "\n",
        "# 填充测试集的缺失值\n",
        "for col in rfm_feature_cols:\n",
        "    if col in test_df.columns:\n",
        "        test_df[col].fillna(fill_values[col], inplace=True)\n",
        "\n",
        "# 填充交互特征的缺失值\n",
        "interaction_features = ['device_province_count', 'channel_device_count', 'operator_city_count']\n",
        "for feature in interaction_features:\n",
        "    if feature in test_df.columns:\n",
        "        test_df[feature].fillna(1, inplace=True)  # 用1填充表示这是新的组合\n",
        "\n",
        "print(\"特征合并完成！\")\n",
        "print(f\"训练集shape: {train_df.shape}\")\n",
        "print(f\"测试集shape: {test_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 类别特征编码 ===\n",
            "特征 device_brand 编码完成，类别数: 213\n",
            "特征 ntt 编码完成，类别数: 6\n",
            "特征 operator 编码完成，类别数: 4\n",
            "特征 common_country 编码完成，类别数: 112\n",
            "特征 common_province 编码完成，类别数: 275\n",
            "特征 common_city 编码完成，类别数: 455\n",
            "特征 appver 编码完成，类别数: 108\n",
            "特征 channel 编码完成，类别数: 18\n",
            "特征 os_type 编码完成，类别数: 2\n",
            "特征 time_period 编码完成，类别数: 4\n",
            "特征 hour_group 编码完成，类别数: 3\n",
            "特征 minute_group 编码完成，类别数: 4\n",
            "特征 user_activity_level 编码完成，类别数: 4\n",
            "特征 user_recency_level 编码完成，类别数: 4\n",
            "类别特征编码完成！\n",
            "CPU times: total: 35.6 s\n",
            "Wall time: 36.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 6. 类别特征编码\n",
        "print(\"=== 类别特征编码 ===\")\n",
        "\n",
        "# 需要编码的类别特征（包括新的时间分组特征）\n",
        "cat_features = [\n",
        "    'device_brand', 'ntt', 'operator', 'common_country',\n",
        "    'common_province', 'common_city', 'appver', 'channel',\n",
        "    'os_type', 'time_period', 'hour_group', 'minute_group',\n",
        "    'user_activity_level', 'user_recency_level'\n",
        "]\n",
        "\n",
        "label_encoders = {}\n",
        "\n",
        "for feature in cat_features:\n",
        "    if feature in train_df.columns and feature in test_df.columns:\n",
        "        le = LabelEncoder()\n",
        "        \n",
        "        # 合并训练集和测试集的所有类别\n",
        "        all_values = pd.concat([train_df[feature], test_df[feature]]).astype(str)\n",
        "        \n",
        "        le.fit(all_values)\n",
        "        label_encoders[feature] = le\n",
        "        \n",
        "        # 应用编码\n",
        "        train_df[feature] = le.transform(train_df[feature].astype(str))\n",
        "        test_df[feature] = le.transform(test_df[feature].astype(str))\n",
        "        \n",
        "        print(f\"特征 {feature} 编码完成，类别数: {len(le.classes_)}\")\n",
        "\n",
        "# udmap处理：由于都是空JSON，我们创建一个简单的特征\n",
        "train_df['udmap_is_empty'] = 1  # 所有都是空的，这个特征值对所有样本都是1\n",
        "test_df['udmap_is_empty'] = 1\n",
        "\n",
        "print(\"类别特征编码完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 特征选择和准备 ===\n",
            "总共定义特征数: 58\n",
            "可用特征数: 58\n",
            "缺失特征: []\n",
            "\n",
            "训练集特征shape: (3429925, 58)\n",
            "测试集特征shape: (1143309, 58)\n",
            "\n",
            "训练集缺失值:\n",
            "hour_consistency         51053\n",
            "dayofweek_consistency    51053\n",
            "ntt_std                  51053\n",
            "dtype: int64\n",
            "\n",
            "测试集缺失值:\n",
            "无缺失值\n",
            "特征准备完成！\n",
            "CPU times: total: 2.2 s\n",
            "Wall time: 2.16 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 7. 特征选择和准备\n",
        "print(\"=== 特征选择和准备 ===\")\n",
        "\n",
        "# 定义完整的特征列表\n",
        "features = [\n",
        "    # 原始特征\n",
        "    'mid', 'eid', 'device_brand', 'ntt', 'operator', \n",
        "    'common_country', 'common_province', 'common_city',\n",
        "    'appver', 'channel', 'os_type',\n",
        "    \n",
        "    # 基础时间特征\n",
        "    'hour', 'dayofweek', 'day', 'minute', 'common_ts',\n",
        "    \n",
        "    # 增强时间特征\n",
        "    'is_weekend', 'is_workday', 'time_period', 'hour_group', 'minute_group',\n",
        "    \n",
        "    # RFM基础特征\n",
        "    'recency_days', 'user_age_days', 'frequency_total', 'frequency_unique',\n",
        "    'monetary_unique', 'first_action_ts', 'last_action_ts',\n",
        "    \n",
        "    # RFM衍生特征\n",
        "    'action_timespan_seconds', 'action_timespan_days', 'actions_per_day',\n",
        "    'unique_action_ratio', 'hour_range',\n",
        "    \n",
        "    # 时间模式特征\n",
        "    'avg_hour', 'hour_consistency', 'earliest_hour', 'latest_hour',\n",
        "    'avg_dayofweek', 'dayofweek_consistency', 'weekend_activity_ratio',\n",
        "    \n",
        "    # 用户多样性特征\n",
        "    'user_device_diversity', 'user_province_diversity', 'user_city_diversity',\n",
        "    'user_channel_diversity', 'user_operator_diversity', 'user_os_diversity',\n",
        "    'user_appver_diversity', 'user_time_diversity',\n",
        "    \n",
        "    # 用户分类特征\n",
        "    'user_activity_level', 'user_recency_level',\n",
        "    \n",
        "    # NTT统计特征\n",
        "    'ntt_mean', 'ntt_std', 'ntt_min', 'ntt_max',\n",
        "    \n",
        "    # 交互特征\n",
        "    'device_province_count', 'channel_device_count', 'operator_city_count',\n",
        "    \n",
        "    # udmap特征\n",
        "    'udmap_is_empty'\n",
        "]\n",
        "\n",
        "# 检查哪些特征实际存在\n",
        "available_features = []\n",
        "missing_features = []\n",
        "\n",
        "for feature in features:\n",
        "    if feature in train_df.columns and feature in test_df.columns:\n",
        "        available_features.append(feature)\n",
        "    else:\n",
        "        missing_features.append(feature)\n",
        "\n",
        "print(f\"总共定义特征数: {len(features)}\")\n",
        "print(f\"可用特征数: {len(available_features)}\")\n",
        "print(f\"缺失特征: {missing_features}\")\n",
        "\n",
        "# 准备训练和测试数据\n",
        "X_train = train_df[available_features]\n",
        "y_train = train_df['is_new_did']\n",
        "X_test = test_df[available_features]\n",
        "\n",
        "print(f\"\\n训练集特征shape: {X_train.shape}\")\n",
        "print(f\"测试集特征shape: {X_test.shape}\")\n",
        "\n",
        "# 检查缺失值\n",
        "print(f\"\\n训练集缺失值:\")\n",
        "missing_train = X_train.isnull().sum()\n",
        "if missing_train.sum() > 0:\n",
        "    print(missing_train[missing_train > 0])\n",
        "else:\n",
        "    print(\"无缺失值\")\n",
        "\n",
        "print(f\"\\n测试集缺失值:\")\n",
        "missing_test = X_test.isnull().sum()\n",
        "if missing_test.sum() > 0:\n",
        "    print(missing_test[missing_test > 0])\n",
        "else:\n",
        "    print(\"无缺失值\")\n",
        "\n",
        "# 清理不需要的列\n",
        "for df in [train_df, test_df]:\n",
        "    if 'ts' in df.columns:\n",
        "        df.drop(['ts'], axis=1, inplace=True)\n",
        "\n",
        "print(\"特征准备完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "模型参数配置完成！\n"
          ]
        }
      ],
      "source": [
        "# F1阈值优化函数\n",
        "def find_optimal_threshold(y_true, y_pred_proba):\n",
        "    \"\"\"寻找最大化F1分数的阈值\"\"\"\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "    \n",
        "    for threshold in [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    \n",
        "    return best_threshold, best_f1\n",
        "\n",
        "# 增强的模型参数\n",
        "enhanced_params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'verbose': -1,\n",
        "    'n_jobs': 8,\n",
        "    'seed': 42,\n",
        "    'max_depth': 15,\n",
        "    'num_leaves': 255,\n",
        "    'learning_rate': 0.08,  # 稍微降低学习率\n",
        "    'min_child_samples': 20,  # 增加最小样本数\n",
        "    'feature_fraction': 0.85,  # 降低特征采样比例\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 3,\n",
        "    'lambda_l1': 0.1,  # 添加L1正则化\n",
        "    'lambda_l2': 0.1,  # 添加L2正则化\n",
        "    'min_gain_to_split': 0.02  # 添加分割增益阈值\n",
        "}\n",
        "\n",
        "print(\"模型参数配置完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 开始训练增强特征模型 ===\n",
            "\n",
            "======= Fold 1/5 =======\n",
            "[200]\ttraining's binary_logloss: 0.106022\tvalid_1's binary_logloss: 0.1103\n",
            "[400]\ttraining's binary_logloss: 0.0808648\tvalid_1's binary_logloss: 0.0878177\n",
            "[600]\ttraining's binary_logloss: 0.0645734\tvalid_1's binary_logloss: 0.0734504\n",
            "[800]\ttraining's binary_logloss: 0.0530016\tvalid_1's binary_logloss: 0.0636413\n",
            "[1000]\ttraining's binary_logloss: 0.0438037\tvalid_1's binary_logloss: 0.055562\n",
            "[1200]\ttraining's binary_logloss: 0.0364335\tvalid_1's binary_logloss: 0.0492146\n",
            "[1400]\ttraining's binary_logloss: 0.0306712\tvalid_1's binary_logloss: 0.0441847\n",
            "Fold 1 Optimal Threshold: 0.4500\n",
            "Fold 1 F1 Score: 0.96194\n",
            "Fold 1 Best Iteration: 1500\n",
            "\n",
            "======= Fold 2/5 =======\n",
            "[200]\ttraining's binary_logloss: 0.106543\tvalid_1's binary_logloss: 0.111079\n",
            "[400]\ttraining's binary_logloss: 0.0808434\tvalid_1's binary_logloss: 0.0879143\n",
            "[600]\ttraining's binary_logloss: 0.0642725\tvalid_1's binary_logloss: 0.0732441\n",
            "[800]\ttraining's binary_logloss: 0.0523375\tvalid_1's binary_logloss: 0.0629595\n",
            "[1000]\ttraining's binary_logloss: 0.0434054\tvalid_1's binary_logloss: 0.0552455\n",
            "[1200]\ttraining's binary_logloss: 0.0364684\tvalid_1's binary_logloss: 0.0494118\n",
            "[1400]\ttraining's binary_logloss: 0.0307262\tvalid_1's binary_logloss: 0.0445993\n",
            "Fold 2 Optimal Threshold: 0.4500\n",
            "Fold 2 F1 Score: 0.96117\n",
            "Fold 2 Best Iteration: 1500\n",
            "\n",
            "======= Fold 3/5 =======\n",
            "[200]\ttraining's binary_logloss: 0.106592\tvalid_1's binary_logloss: 0.110149\n",
            "[400]\ttraining's binary_logloss: 0.0810082\tvalid_1's binary_logloss: 0.0873708\n",
            "[600]\ttraining's binary_logloss: 0.0644592\tvalid_1's binary_logloss: 0.072999\n",
            "[800]\ttraining's binary_logloss: 0.052537\tvalid_1's binary_logloss: 0.0627997\n",
            "[1000]\ttraining's binary_logloss: 0.0436304\tvalid_1's binary_logloss: 0.0552472\n",
            "[1200]\ttraining's binary_logloss: 0.0365671\tvalid_1's binary_logloss: 0.049306\n",
            "[1400]\ttraining's binary_logloss: 0.0307701\tvalid_1's binary_logloss: 0.0443476\n",
            "Fold 3 Optimal Threshold: 0.4500\n",
            "Fold 3 F1 Score: 0.96185\n",
            "Fold 3 Best Iteration: 1500\n",
            "\n",
            "======= Fold 4/5 =======\n",
            "[200]\ttraining's binary_logloss: 0.106797\tvalid_1's binary_logloss: 0.111151\n",
            "[400]\ttraining's binary_logloss: 0.0806218\tvalid_1's binary_logloss: 0.087591\n",
            "[600]\ttraining's binary_logloss: 0.0642829\tvalid_1's binary_logloss: 0.0732546\n",
            "[800]\ttraining's binary_logloss: 0.0523603\tvalid_1's binary_logloss: 0.0629122\n",
            "[1000]\ttraining's binary_logloss: 0.043422\tvalid_1's binary_logloss: 0.0551406\n",
            "[1200]\ttraining's binary_logloss: 0.036368\tvalid_1's binary_logloss: 0.0489514\n",
            "[1400]\ttraining's binary_logloss: 0.0306167\tvalid_1's binary_logloss: 0.0441381\n",
            "Fold 4 Optimal Threshold: 0.4500\n",
            "Fold 4 F1 Score: 0.96127\n",
            "Fold 4 Best Iteration: 1500\n",
            "\n",
            "======= Fold 5/5 =======\n",
            "[200]\ttraining's binary_logloss: 0.107349\tvalid_1's binary_logloss: 0.111152\n",
            "[400]\ttraining's binary_logloss: 0.0810842\tvalid_1's binary_logloss: 0.0876088\n",
            "[600]\ttraining's binary_logloss: 0.0644981\tvalid_1's binary_logloss: 0.0730361\n",
            "[800]\ttraining's binary_logloss: 0.052694\tvalid_1's binary_logloss: 0.062649\n",
            "[1000]\ttraining's binary_logloss: 0.0436647\tvalid_1's binary_logloss: 0.0549295\n",
            "[1200]\ttraining's binary_logloss: 0.0364536\tvalid_1's binary_logloss: 0.0487661\n",
            "[1400]\ttraining's binary_logloss: 0.0308188\tvalid_1's binary_logloss: 0.0438993\n",
            "Fold 5 Optimal Threshold: 0.5000\n",
            "Fold 5 F1 Score: 0.96183\n",
            "Fold 5 Best Iteration: 1500\n",
            "\n",
            "=== 模型训练完成 ===\n",
            "CPU times: total: 2h 59min 39s\n",
            "Wall time: 21min 43s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 8. 增强特征模型训练\n",
        "print(\"=== 开始训练增强特征模型 ===\")\n",
        "\n",
        "n_folds = 5\n",
        "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "test_preds = np.zeros(len(X_test))\n",
        "fold_thresholds = []\n",
        "fold_f1_scores = []\n",
        "models = []\n",
        "oof_preds = np.zeros(len(X_train))\n",
        "oof_probas = np.zeros(len(X_train))\n",
        "\n",
        "# 特征重要性存储\n",
        "feature_importance_df = pd.DataFrame()\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
        "    print(f\"\\n======= Fold {fold+1}/{n_folds} =======\")\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "    \n",
        "    # 创建数据集\n",
        "    train_set = lgb.Dataset(X_tr, label=y_tr)\n",
        "    val_set = lgb.Dataset(X_val, label=y_val)\n",
        "    \n",
        "    # 模型训练\n",
        "    model = lgb.train(\n",
        "        enhanced_params, train_set,\n",
        "        num_boost_round=1500,  # 增加训练轮数\n",
        "        valid_sets=[train_set, val_set],\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100, verbose=False),  # 增加早停轮数\n",
        "            lgb.log_evaluation(period=200)\n",
        "        ]\n",
        "    )\n",
        "    models.append(model)\n",
        "    \n",
        "    # 记录特征重要性\n",
        "    fold_importance = pd.DataFrame()\n",
        "    fold_importance['feature'] = X_train.columns\n",
        "    fold_importance['importance'] = model.feature_importance(importance_type='gain')\n",
        "    fold_importance['fold'] = fold + 1\n",
        "    feature_importance_df = pd.concat([feature_importance_df, fold_importance], axis=0)\n",
        "    \n",
        "    # 验证集预测\n",
        "    val_pred_proba = model.predict(X_val)\n",
        "    oof_probas[val_idx] = val_pred_proba\n",
        "    \n",
        "    # 阈值优化\n",
        "    best_threshold, best_f1 = find_optimal_threshold(y_val, val_pred_proba)\n",
        "    fold_thresholds.append(best_threshold)\n",
        "    \n",
        "    # 使用优化阈值计算F1\n",
        "    val_pred_labels = (val_pred_proba >= best_threshold).astype(int)\n",
        "    fold_f1 = f1_score(y_val, val_pred_labels)\n",
        "    fold_f1_scores.append(fold_f1)\n",
        "    oof_preds[val_idx] = val_pred_labels\n",
        "    \n",
        "    print(f\"Fold {fold+1} Optimal Threshold: {best_threshold:.4f}\")\n",
        "    print(f\"Fold {fold+1} F1 Score: {fold_f1:.5f}\")\n",
        "    print(f\"Fold {fold+1} Best Iteration: {model.best_iteration}\")\n",
        "    \n",
        "    # 测试集预测\n",
        "    test_preds += model.predict(X_test) / n_folds\n",
        "\n",
        "print(\"\\n=== 模型训练完成 ===\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== 修复数据泄露后的最终结果 =====\n",
            "Average Optimal Threshold: 0.4600\n",
            "Fold F1 Scores: ['0.96194', '0.96117', '0.96185', '0.96127', '0.96183']\n",
            "Average Fold F1: 0.96161\n",
            "OOF F1 Score: 0.96177\n",
            "\n",
            "修复数据泄露后的提交文件已保存: submit_fixed.csv\n",
            "预测新用户比例: 0.1486\n",
            "测试集大小: 1143309\n"
          ]
        }
      ],
      "source": [
        "# 整体结果评估\n",
        "avg_threshold = np.mean(fold_thresholds)\n",
        "final_oof_preds = (oof_probas >= avg_threshold).astype(int)\n",
        "final_f1 = f1_score(y_train, final_oof_preds)\n",
        "\n",
        "print(\"\\n===== 修复数据泄露后的最终结果 =====\")\n",
        "print(f\"Average Optimal Threshold: {avg_threshold:.4f}\")\n",
        "print(f\"Fold F1 Scores: {[f'{s:.5f}' for s in fold_f1_scores]}\")\n",
        "print(f\"Average Fold F1: {np.mean(fold_f1_scores):.5f}\")\n",
        "print(f\"OOF F1 Score: {final_f1:.5f}\")\n",
        "\n",
        "# 测试集预测与提交文件生成\n",
        "test_pred_labels = (test_preds >= avg_threshold).astype(int)\n",
        "submit['is_new_did'] = test_pred_labels\n",
        "\n",
        "# 保存提交文件\n",
        "submit[['is_new_did']].to_csv('submit_fixed.csv', index=False)\n",
        "print(\"\\n修复数据泄露后的提交文件已保存: submit_fixed.csv\")\n",
        "print(f\"预测新用户比例: {test_pred_labels.mean():.4f}\")\n",
        "print(f\"测试集大小: {len(test_pred_labels)}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
