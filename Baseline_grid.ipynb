{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818bfa3a-c87e-4990-96d8-745291e61064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:07:38.276684Z",
     "iopub.status.busy": "2025-07-17T16:07:38.276433Z",
     "iopub.status.idle": "2025-07-17T16:07:39.458137Z",
     "shell.execute_reply": "2025-07-17T16:07:39.457568Z",
     "shell.execute_reply.started": "2025-07-17T16:07:38.276667Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ba47ba-b3fe-474b-aceb-0886694516a4",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-07-17T16:07:39.459353Z",
     "iopub.status.busy": "2025-07-17T16:07:39.459031Z",
     "iopub.status.idle": "2025-07-17T16:07:48.024548Z",
     "shell.execute_reply": "2025-07-17T16:07:48.023945Z",
     "shell.execute_reply.started": "2025-07-17T16:07:39.459338Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.84 s, sys: 1.69 s, total: 8.53 s\n",
      "Wall time: 8.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1. 数据加载\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./testA_data.csv')\n",
    "submit = test_df[['did']]\n",
    "\n",
    "full_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# 2. 时间特征工程\n",
    "for df in [train_df, test_df]:\n",
    "    # 转换为时间戳\n",
    "    df['ts'] = pd.to_datetime(df['common_ts'], unit='ms')\n",
    "    \n",
    "    # 提取时间特征\n",
    "    df['day'] = df['ts'].dt.day\n",
    "    df['dayofweek'] = df['ts'].dt.dayofweek\n",
    "    df['hour'] = df['ts'].dt.hour\n",
    "\n",
    "# 对 full_df 进行同样的处理，用于计算全局聚合特征\n",
    "full_df['ts'] = pd.to_datetime(full_df['common_ts'], unit='ms')\n",
    "full_df['day'] = full_df['ts'].dt.day\n",
    "full_df['dayofweek'] = full_df['ts'].dt.dayofweek\n",
    "full_df['hour'] = full_df['ts'].dt.hour\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1afb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:07:48.025518Z",
     "iopub.status.busy": "2025-07-17T16:07:48.025202Z",
     "iopub.status.idle": "2025-07-17T16:08:09.038558Z",
     "shell.execute_reply": "2025-07-17T16:08:09.038009Z",
     "shell.execute_reply.started": "2025-07-17T16:07:48.025497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.2 s, sys: 786 ms, total: 21 s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3. RFM 特征工程\n",
    "\n",
    "# 3.1 RFM 特征构建\n",
    "# 我们在 full_df 上计算这些聚合特征，因为它包含了所有用户的所有行为\n",
    "max_ts = full_df['ts'].max()\n",
    "rfm_agg = full_df.groupby('did').agg({\n",
    "    'ts': lambda x: (max_ts - x.max()).days, # Recency\n",
    "    'eid': 'count', # Frequency\n",
    "    'mid': 'nunique', # 行为深度\n",
    "    'common_ts': ['min', 'max'] # 首次和末次行为时间\n",
    "})\n",
    "\n",
    "# 3.2 列名扁平化处理\n",
    "# 将多级索引 ('common_ts', 'min') 合并为单级 'common_ts_min'\n",
    "rfm_agg.columns = ['_'.join(col).strip() for col in rfm_agg.columns.values]\n",
    "rfm_agg = rfm_agg.reset_index()\n",
    "\n",
    "# 3.3 特征重命名\n",
    "rfm_agg.rename(columns={\n",
    "    'ts_<lambda>': 'recency',\n",
    "    'eid_count': 'frequency',\n",
    "    'mid_nunique': 'mid_nunique',\n",
    "    'common_ts_min': 'first_action_ts',\n",
    "    'common_ts_max': 'last_action_ts'\n",
    "}, inplace=True)\n",
    "\n",
    "# 3.4 派生新特征\n",
    "# 计算首次和末次行为的时间跨度（单位：秒）\n",
    "rfm_agg['action_timespan_seconds'] = (rfm_agg['last_action_ts'] - rfm_agg['first_action_ts']) / 1000\n",
    "\n",
    "# 3.5 合并RFM特征到 train_df 和 test_df\n",
    "# 为了确保后续流程的变量一致性，我们直接在 train_df 和 test_df 上合并\n",
    "train_df = pd.merge(train_df, rfm_agg, on='did', how='left')\n",
    "test_df = pd.merge(test_df, rfm_agg, on='did', how='left')\n",
    "\n",
    "# 3.6 清理不再需要的 ts 列\n",
    "for df in [train_df, test_df]:\n",
    "    df.drop(['ts'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf134ea-e601-4556-9858-303f040d74ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:08:09.039399Z",
     "iopub.status.busy": "2025-07-17T16:08:09.039154Z",
     "iopub.status.idle": "2025-07-17T16:08:28.838287Z",
     "shell.execute_reply": "2025-07-17T16:08:28.837826Z",
     "shell.execute_reply.started": "2025-07-17T16:08:09.039382Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 2.12 s, total: 19.8 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 需要编码的特征列表\n",
    "cat_features = [\n",
    "    'device_brand', 'ntt', 'operator', 'common_country',\n",
    "    'common_province', 'common_city', 'appver', 'channel',\n",
    "    'os_type', 'udmap'\n",
    "]\n",
    "# 初始化编码器字典\n",
    "label_encoders = {}\n",
    "\n",
    "for feature in cat_features:\n",
    "    # 创建编码器，将类别特征转为0-N的自然数\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # 合并训练集和测试集的所有类别\n",
    "    all_values = pd.concat([train_df[feature], test_df[feature]]).astype(str)\n",
    "    \n",
    "    # 训练编码器（使用所有可能值）\n",
    "    le.fit(all_values)\n",
    "    \n",
    "    # 保存编码器\n",
    "    label_encoders[feature] = le\n",
    "    \n",
    "    # 应用编码\n",
    "    train_df[feature] = le.transform(train_df[feature].astype(str))\n",
    "    test_df[feature] = le.transform(test_df[feature].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bc120b-7fa4-45b5-8c56-097cddaa8bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:08:28.839516Z",
     "iopub.status.busy": "2025-07-17T16:08:28.839295Z",
     "iopub.status.idle": "2025-07-17T16:08:29.227791Z",
     "shell.execute_reply": "2025-07-17T16:08:29.227232Z",
     "shell.execute_reply.started": "2025-07-17T16:08:28.839500Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 151 ms, sys: 234 ms, total: 385 ms\n",
      "Wall time: 384 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 基础特征 + 目标编码特征 + 聚合特征\n",
    "features = [\n",
    "    # 原始特征\n",
    "    'mid', 'eid', 'device_brand', 'ntt', 'operator', \n",
    "    'common_country', 'common_province', 'common_city',\n",
    "    'appver', 'channel', 'os_type', 'udmap',\n",
    "    # 时间特征\n",
    "    'hour', 'dayofweek', 'day', 'common_ts',\n",
    "    # RFM特征\n",
    "   'recency', 'frequency', 'mid_nunique', 'first_action_ts', 'last_action_ts', 'action_timespan_seconds'\n",
    "]\n",
    "\n",
    "# 准备训练和测试数据\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['is_new_did']\n",
    "X_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb98dd6b-bece-4f83-988f-40787fc136c9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-07-17T16:08:29.228688Z",
     "iopub.status.busy": "2025-07-17T16:08:29.228519Z",
     "iopub.status.idle": "2025-07-17T19:34:59.211406Z",
     "shell.execute_reply": "2025-07-17T19:34:59.210931Z",
     "shell.execute_reply.started": "2025-07-17T16:08:29.228673Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始网格搜索参数优化...\n",
      "\n",
      "=== 第一阶段：搜索核心结构参数 ===\n",
      "进度: 1/64 | max_depth=8, num_leaves=31, lr=0.05, min_child=10 | F1=0.77430\n",
      "*** 新的最佳结果! F1=0.77430 ***\n",
      "进度: 2/64 | max_depth=8, num_leaves=31, lr=0.05, min_child=20 | F1=0.77424\n",
      "进度: 3/64 | max_depth=8, num_leaves=31, lr=0.1, min_child=10 | F1=0.79413\n",
      "*** 新的最佳结果! F1=0.79413 ***\n",
      "进度: 4/64 | max_depth=8, num_leaves=31, lr=0.1, min_child=20 | F1=0.79383\n",
      "进度: 5/64 | max_depth=8, num_leaves=63, lr=0.05, min_child=10 | F1=0.79375\n",
      "进度: 6/64 | max_depth=8, num_leaves=63, lr=0.05, min_child=20 | F1=0.79341\n",
      "进度: 7/64 | max_depth=8, num_leaves=63, lr=0.1, min_child=10 | F1=0.81757\n",
      "*** 新的最佳结果! F1=0.81757 ***\n",
      "进度: 8/64 | max_depth=8, num_leaves=63, lr=0.1, min_child=20 | F1=0.81755\n",
      "进度: 9/64 | max_depth=8, num_leaves=127, lr=0.05, min_child=10 | F1=0.81161\n",
      "进度: 10/64 | max_depth=8, num_leaves=127, lr=0.05, min_child=20 | F1=0.81116\n",
      "进度: 11/64 | max_depth=8, num_leaves=127, lr=0.1, min_child=10 | F1=0.84097\n",
      "*** 新的最佳结果! F1=0.84097 ***\n",
      "进度: 12/64 | max_depth=8, num_leaves=127, lr=0.1, min_child=20 | F1=0.84127\n",
      "*** 新的最佳结果! F1=0.84127 ***\n",
      "进度: 13/64 | max_depth=8, num_leaves=255, lr=0.05, min_child=10 | F1=0.81679\n",
      "进度: 14/64 | max_depth=8, num_leaves=255, lr=0.05, min_child=20 | F1=0.81617\n",
      "进度: 15/64 | max_depth=8, num_leaves=255, lr=0.1, min_child=10 | F1=0.84867\n",
      "*** 新的最佳结果! F1=0.84867 ***\n",
      "进度: 16/64 | max_depth=8, num_leaves=255, lr=0.1, min_child=20 | F1=0.84837\n",
      "进度: 17/64 | max_depth=10, num_leaves=31, lr=0.05, min_child=10 | F1=0.77509\n",
      "进度: 18/64 | max_depth=10, num_leaves=31, lr=0.05, min_child=20 | F1=0.77461\n",
      "进度: 19/64 | max_depth=10, num_leaves=31, lr=0.1, min_child=10 | F1=0.79477\n",
      "进度: 20/64 | max_depth=10, num_leaves=31, lr=0.1, min_child=20 | F1=0.79517\n",
      "进度: 21/64 | max_depth=10, num_leaves=63, lr=0.05, min_child=10 | F1=0.79596\n",
      "进度: 22/64 | max_depth=10, num_leaves=63, lr=0.05, min_child=20 | F1=0.79587\n",
      "进度: 23/64 | max_depth=10, num_leaves=63, lr=0.1, min_child=10 | F1=0.82136\n",
      "进度: 24/64 | max_depth=10, num_leaves=63, lr=0.1, min_child=20 | F1=0.82158\n",
      "进度: 25/64 | max_depth=10, num_leaves=127, lr=0.05, min_child=10 | F1=0.82072\n",
      "进度: 26/64 | max_depth=10, num_leaves=127, lr=0.05, min_child=20 | F1=0.82139\n",
      "进度: 27/64 | max_depth=10, num_leaves=127, lr=0.1, min_child=10 | F1=0.85340\n",
      "*** 新的最佳结果! F1=0.85340 ***\n",
      "进度: 28/64 | max_depth=10, num_leaves=127, lr=0.1, min_child=20 | F1=0.85250\n",
      "进度: 29/64 | max_depth=10, num_leaves=255, lr=0.05, min_child=10 | F1=0.84813\n",
      "进度: 30/64 | max_depth=10, num_leaves=255, lr=0.05, min_child=20 | F1=0.84762\n",
      "进度: 31/64 | max_depth=10, num_leaves=255, lr=0.1, min_child=10 | F1=0.88395\n",
      "*** 新的最佳结果! F1=0.88395 ***\n",
      "进度: 32/64 | max_depth=10, num_leaves=255, lr=0.1, min_child=20 | F1=0.88407\n",
      "*** 新的最佳结果! F1=0.88407 ***\n",
      "进度: 33/64 | max_depth=12, num_leaves=31, lr=0.05, min_child=10 | F1=0.77553\n",
      "进度: 34/64 | max_depth=12, num_leaves=31, lr=0.05, min_child=20 | F1=0.77565\n",
      "进度: 35/64 | max_depth=12, num_leaves=31, lr=0.1, min_child=10 | F1=0.79582\n",
      "进度: 36/64 | max_depth=12, num_leaves=31, lr=0.1, min_child=20 | F1=0.79535\n",
      "进度: 37/64 | max_depth=12, num_leaves=63, lr=0.05, min_child=10 | F1=0.79690\n",
      "进度: 38/64 | max_depth=12, num_leaves=63, lr=0.05, min_child=20 | F1=0.79713\n",
      "进度: 39/64 | max_depth=12, num_leaves=63, lr=0.1, min_child=10 | F1=0.82334\n",
      "进度: 40/64 | max_depth=12, num_leaves=63, lr=0.1, min_child=20 | F1=0.82346\n",
      "进度: 41/64 | max_depth=12, num_leaves=127, lr=0.05, min_child=10 | F1=0.82446\n",
      "进度: 42/64 | max_depth=12, num_leaves=127, lr=0.05, min_child=20 | F1=0.82406\n",
      "进度: 43/64 | max_depth=12, num_leaves=127, lr=0.1, min_child=10 | F1=0.85703\n",
      "进度: 44/64 | max_depth=12, num_leaves=127, lr=0.1, min_child=20 | F1=0.85722\n",
      "进度: 45/64 | max_depth=12, num_leaves=255, lr=0.05, min_child=10 | F1=0.85682\n",
      "进度: 46/64 | max_depth=12, num_leaves=255, lr=0.05, min_child=20 | F1=0.85682\n",
      "进度: 47/64 | max_depth=12, num_leaves=255, lr=0.1, min_child=10 | F1=0.89332\n",
      "*** 新的最佳结果! F1=0.89332 ***\n",
      "进度: 48/64 | max_depth=12, num_leaves=255, lr=0.1, min_child=20 | F1=0.89295\n",
      "进度: 49/64 | max_depth=15, num_leaves=31, lr=0.05, min_child=10 | F1=0.77495\n",
      "进度: 50/64 | max_depth=15, num_leaves=31, lr=0.05, min_child=20 | F1=0.77489\n",
      "进度: 51/64 | max_depth=15, num_leaves=31, lr=0.1, min_child=10 | F1=0.79582\n",
      "进度: 52/64 | max_depth=15, num_leaves=31, lr=0.1, min_child=20 | F1=0.79576\n",
      "进度: 53/64 | max_depth=15, num_leaves=63, lr=0.05, min_child=10 | F1=0.79738\n",
      "进度: 54/64 | max_depth=15, num_leaves=63, lr=0.05, min_child=20 | F1=0.79719\n",
      "进度: 55/64 | max_depth=15, num_leaves=63, lr=0.1, min_child=10 | F1=0.82442\n",
      "进度: 56/64 | max_depth=15, num_leaves=63, lr=0.1, min_child=20 | F1=0.82477\n",
      "进度: 57/64 | max_depth=15, num_leaves=127, lr=0.05, min_child=10 | F1=0.82674\n",
      "进度: 58/64 | max_depth=15, num_leaves=127, lr=0.05, min_child=20 | F1=0.82655\n",
      "进度: 59/64 | max_depth=15, num_leaves=127, lr=0.1, min_child=10 | F1=0.86054\n",
      "进度: 60/64 | max_depth=15, num_leaves=127, lr=0.1, min_child=20 | F1=0.86100\n",
      "进度: 61/64 | max_depth=15, num_leaves=255, lr=0.05, min_child=10 | F1=0.86194\n",
      "进度: 62/64 | max_depth=15, num_leaves=255, lr=0.05, min_child=20 | F1=0.86174\n",
      "进度: 63/64 | max_depth=15, num_leaves=255, lr=0.1, min_child=10 | F1=0.89853\n",
      "*** 新的最佳结果! F1=0.89853 ***\n",
      "进度: 64/64 | max_depth=15, num_leaves=255, lr=0.1, min_child=20 | F1=0.89760\n",
      "\n",
      "第一阶段最佳参数: {'max_depth': 15, 'num_leaves': 255, 'learning_rate': 0.1, 'min_child_samples': 10}\n",
      "第一阶段最佳F1: 0.89853\n",
      "\n",
      "=== 第二阶段：搜索正则化参数 ===\n",
      "feature_frac=0.6, bagging_frac=0.7, bagging_freq=3 | F1=0.89749\n",
      "feature_frac=0.6, bagging_frac=0.7, bagging_freq=5 | F1=0.89746\n",
      "feature_frac=0.6, bagging_frac=0.7, bagging_freq=7 | F1=0.89763\n",
      "feature_frac=0.6, bagging_frac=0.8, bagging_freq=3 | F1=0.89723\n",
      "feature_frac=0.6, bagging_frac=0.8, bagging_freq=5 | F1=0.89766\n",
      "feature_frac=0.6, bagging_frac=0.8, bagging_freq=7 | F1=0.89651\n",
      "feature_frac=0.6, bagging_frac=0.9, bagging_freq=3 | F1=0.89639\n",
      "feature_frac=0.6, bagging_frac=0.9, bagging_freq=5 | F1=0.89694\n",
      "feature_frac=0.6, bagging_frac=0.9, bagging_freq=7 | F1=0.89598\n",
      "feature_frac=0.7, bagging_frac=0.7, bagging_freq=3 | F1=0.89947\n",
      "*** 新的最佳结果! F1=0.89947 ***\n",
      "feature_frac=0.7, bagging_frac=0.7, bagging_freq=5 | F1=0.89892\n",
      "feature_frac=0.7, bagging_frac=0.7, bagging_freq=7 | F1=0.89789\n",
      "feature_frac=0.7, bagging_frac=0.8, bagging_freq=3 | F1=0.89856\n",
      "feature_frac=0.7, bagging_frac=0.8, bagging_freq=5 | F1=0.89870\n",
      "feature_frac=0.7, bagging_frac=0.8, bagging_freq=7 | F1=0.89862\n",
      "feature_frac=0.7, bagging_frac=0.9, bagging_freq=3 | F1=0.89801\n",
      "feature_frac=0.7, bagging_frac=0.9, bagging_freq=5 | F1=0.89796\n",
      "feature_frac=0.7, bagging_frac=0.9, bagging_freq=7 | F1=0.89854\n",
      "feature_frac=0.8, bagging_frac=0.7, bagging_freq=3 | F1=0.90167\n",
      "*** 新的最佳结果! F1=0.90167 ***\n",
      "feature_frac=0.8, bagging_frac=0.7, bagging_freq=5 | F1=0.90140\n",
      "feature_frac=0.8, bagging_frac=0.7, bagging_freq=7 | F1=0.90080\n",
      "feature_frac=0.8, bagging_frac=0.8, bagging_freq=3 | F1=0.90114\n",
      "feature_frac=0.8, bagging_frac=0.8, bagging_freq=5 | F1=0.90012\n",
      "feature_frac=0.8, bagging_frac=0.8, bagging_freq=7 | F1=0.90146\n",
      "feature_frac=0.8, bagging_frac=0.9, bagging_freq=3 | F1=0.90057\n",
      "feature_frac=0.8, bagging_frac=0.9, bagging_freq=5 | F1=0.90005\n",
      "feature_frac=0.8, bagging_frac=0.9, bagging_freq=7 | F1=0.89935\n",
      "feature_frac=0.9, bagging_frac=0.7, bagging_freq=3 | F1=0.90204\n",
      "*** 新的最佳结果! F1=0.90204 ***\n",
      "feature_frac=0.9, bagging_frac=0.7, bagging_freq=5 | F1=0.90184\n",
      "feature_frac=0.9, bagging_frac=0.7, bagging_freq=7 | F1=0.90170\n",
      "feature_frac=0.9, bagging_frac=0.8, bagging_freq=3 | F1=0.90227\n",
      "*** 新的最佳结果! F1=0.90227 ***\n",
      "feature_frac=0.9, bagging_frac=0.8, bagging_freq=5 | F1=0.90141\n",
      "feature_frac=0.9, bagging_frac=0.8, bagging_freq=7 | F1=0.90166\n",
      "feature_frac=0.9, bagging_frac=0.9, bagging_freq=3 | F1=0.90080\n",
      "feature_frac=0.9, bagging_frac=0.9, bagging_freq=5 | F1=0.90117\n",
      "feature_frac=0.9, bagging_frac=0.9, bagging_freq=7 | F1=0.90174\n",
      "\n",
      "最终最佳参数: {'objective': 'binary', 'metric': 'binary_logloss', 'verbose': -1, 'n_jobs': 8, 'seed': 42, 'max_depth': 15, 'num_leaves': 255, 'learning_rate': 0.1, 'min_child_samples': 10, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'bagging_freq': 3}\n",
      "最终最佳F1: 0.90227\n",
      "CPU times: user 1d 1h 17min, sys: 3min 7s, total: 1d 1h 20min 7s\n",
      "Wall time: 3h 26min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 6. F1阈值优化函数\n",
    "def find_optimal_threshold(y_true, y_pred_proba):\n",
    "    \"\"\"寻找最大化F1分数的阈值\"\"\"\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "    \n",
    "    for threshold in [0.1,0.15,0.2,0.25,0.3,0.35,0.4]:\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# 7. 网格搜索参数优化\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "def evaluate_params(params_dict, X_train, y_train, n_folds=3):\n",
    "    \"\"\"评估单组参数的性能\"\"\"\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    fold_f1_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # 创建数据集\n",
    "        train_set = lgb.Dataset(X_tr, label=y_tr)\n",
    "        val_set = lgb.Dataset(X_val, label=y_val)\n",
    "        \n",
    "        # 模型训练\n",
    "        model = lgb.train(\n",
    "            params_dict, train_set,\n",
    "            num_boost_round=500,  # 减少轮数以加快搜索\n",
    "            valid_sets=[val_set],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=30, verbose=False),\n",
    "                lgb.log_evaluation(period=0)  # 不输出训练日志\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 预测并计算F1\n",
    "        val_pred_proba = model.predict(X_val)\n",
    "        best_threshold, best_f1 = find_optimal_threshold(y_val, val_pred_proba)\n",
    "        fold_f1_scores.append(best_f1)\n",
    "    \n",
    "    return np.mean(fold_f1_scores)\n",
    "\n",
    "def grid_search_lgb(X_train, y_train):\n",
    "    \"\"\"LightGBM网格搜索\"\"\"\n",
    "    print(\"开始网格搜索参数优化...\")\n",
    "    \n",
    "    # 基础参数\n",
    "    base_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbose': -1,\n",
    "        'n_jobs': 8,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # 第一阶段：搜索核心结构参数\n",
    "    print(\"\\n=== 第一阶段：搜索核心结构参数 ===\")\n",
    "    structure_params = {\n",
    "        'max_depth': [8, 10, 12, 15],\n",
    "        'num_leaves': [31, 63, 127, 255],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'min_child_samples': [10, 20]\n",
    "    }\n",
    "    \n",
    "    best_score = 0\n",
    "    best_structure_params = {}\n",
    "    \n",
    "    total_combinations = len(list(product(*structure_params.values())))\n",
    "    current_combination = 0\n",
    "    \n",
    "    for max_depth, num_leaves, lr, min_child in product(*structure_params.values()):\n",
    "        current_combination += 1\n",
    "        \n",
    "        # 确保 num_leaves < 2^max_depth\n",
    "        if num_leaves >= 2**max_depth:\n",
    "            continue\n",
    "            \n",
    "        params = base_params.copy()\n",
    "        params.update({\n",
    "            'max_depth': max_depth,\n",
    "            'num_leaves': num_leaves,\n",
    "            'learning_rate': lr,\n",
    "            'min_child_samples': min_child,\n",
    "            'feature_fraction': 0.7,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            score = evaluate_params(params, X_train, y_train, n_folds=3)\n",
    "            print(f\"进度: {current_combination}/{total_combinations} | \"\n",
    "                  f\"max_depth={max_depth}, num_leaves={num_leaves}, lr={lr}, min_child={min_child} | \"\n",
    "                  f\"F1={score:.5f}\")\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_structure_params = {\n",
    "                    'max_depth': max_depth,\n",
    "                    'num_leaves': num_leaves,\n",
    "                    'learning_rate': lr,\n",
    "                    'min_child_samples': min_child\n",
    "                }\n",
    "                print(f\"*** 新的最佳结果! F1={best_score:.5f} ***\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"参数组合出错: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n第一阶段最佳参数: {best_structure_params}\")\n",
    "    print(f\"第一阶段最佳F1: {best_score:.5f}\")\n",
    "    \n",
    "    # 第二阶段：基于最佳结构参数，搜索正则化参数\n",
    "    print(\"\\n=== 第二阶段：搜索正则化参数 ===\")\n",
    "    regularization_params = {\n",
    "        'feature_fraction': [0.6, 0.7, 0.8, 0.9],\n",
    "        'bagging_fraction': [0.7, 0.8, 0.9],\n",
    "        'bagging_freq': [3, 5, 7]\n",
    "    }\n",
    "    \n",
    "    best_final_score = best_score\n",
    "    best_final_params = best_structure_params.copy()\n",
    "    best_final_params.update({'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'bagging_freq': 5})\n",
    "    \n",
    "    for feature_frac, bagging_frac, bagging_freq in product(*regularization_params.values()):\n",
    "        params = base_params.copy()\n",
    "        params.update(best_structure_params)\n",
    "        params.update({\n",
    "            'feature_fraction': feature_frac,\n",
    "            'bagging_fraction': bagging_frac,\n",
    "            'bagging_freq': bagging_freq\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            score = evaluate_params(params, X_train, y_train, n_folds=3)\n",
    "            print(f\"feature_frac={feature_frac}, bagging_frac={bagging_frac}, bagging_freq={bagging_freq} | F1={score:.5f}\")\n",
    "            \n",
    "            if score > best_final_score:\n",
    "                best_final_score = score\n",
    "                best_final_params = params.copy()\n",
    "                print(f\"*** 新的最佳结果! F1={best_final_score:.5f} ***\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"参数组合出错: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n最终最佳参数: {best_final_params}\")\n",
    "    print(f\"最终最佳F1: {best_final_score:.5f}\")\n",
    "    \n",
    "    return best_final_params\n",
    "\n",
    "# 执行网格搜索\n",
    "optimal_params = grid_search_lgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f8c9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T19:34:59.212147Z",
     "iopub.status.busy": "2025-07-17T19:34:59.211925Z",
     "iopub.status.idle": "2025-07-17T19:43:44.980309Z",
     "shell.execute_reply": "2025-07-17T19:43:44.979573Z",
     "shell.execute_reply.started": "2025-07-17T19:34:59.212134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始使用最优参数进行最终模型训练...\n",
      "\n",
      "使用最优参数: {'objective': 'binary', 'metric': 'binary_logloss', 'verbose': -1, 'n_jobs': 8, 'seed': 42, 'max_depth': 15, 'num_leaves': 255, 'learning_rate': 0.1, 'min_child_samples': 10, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'bagging_freq': 3}\n",
      "\n",
      "======= Fold 1/5 =======\n",
      "[100]\ttraining's binary_logloss: 0.128682\tvalid_1's binary_logloss: 0.131402\n",
      "[200]\ttraining's binary_logloss: 0.10665\tvalid_1's binary_logloss: 0.111234\n",
      "[300]\ttraining's binary_logloss: 0.0927849\tvalid_1's binary_logloss: 0.0989797\n",
      "[400]\ttraining's binary_logloss: 0.0821904\tvalid_1's binary_logloss: 0.0897463\n",
      "[500]\ttraining's binary_logloss: 0.0734899\tvalid_1's binary_logloss: 0.0821717\n",
      "[600]\ttraining's binary_logloss: 0.0660219\tvalid_1's binary_logloss: 0.0756615\n",
      "[700]\ttraining's binary_logloss: 0.0596661\tvalid_1's binary_logloss: 0.0701872\n",
      "[800]\ttraining's binary_logloss: 0.0541556\tvalid_1's binary_logloss: 0.0654413\n",
      "[900]\ttraining's binary_logloss: 0.0495781\tvalid_1's binary_logloss: 0.0616011\n",
      "[1000]\ttraining's binary_logloss: 0.0451557\tvalid_1's binary_logloss: 0.0578338\n",
      "Fold 1 Optimal Threshold: 0.4000\n",
      "Fold 1 F1 Score: 0.93985\n",
      "\n",
      "======= Fold 2/5 =======\n",
      "[100]\ttraining's binary_logloss: 0.128569\tvalid_1's binary_logloss: 0.131374\n",
      "[200]\ttraining's binary_logloss: 0.106497\tvalid_1's binary_logloss: 0.111332\n",
      "[300]\ttraining's binary_logloss: 0.0924162\tvalid_1's binary_logloss: 0.0988675\n",
      "[400]\ttraining's binary_logloss: 0.0818245\tvalid_1's binary_logloss: 0.089511\n",
      "[500]\ttraining's binary_logloss: 0.0734694\tvalid_1's binary_logloss: 0.0823783\n",
      "[600]\ttraining's binary_logloss: 0.0660397\tvalid_1's binary_logloss: 0.0760917\n",
      "[700]\ttraining's binary_logloss: 0.0596325\tvalid_1's binary_logloss: 0.0706003\n",
      "[800]\ttraining's binary_logloss: 0.0538221\tvalid_1's binary_logloss: 0.0656527\n",
      "[900]\ttraining's binary_logloss: 0.0487806\tvalid_1's binary_logloss: 0.0613578\n",
      "[1000]\ttraining's binary_logloss: 0.0447317\tvalid_1's binary_logloss: 0.0580074\n",
      "Fold 2 Optimal Threshold: 0.4000\n",
      "Fold 2 F1 Score: 0.93913\n",
      "\n",
      "======= Fold 3/5 =======\n",
      "[100]\ttraining's binary_logloss: 0.128362\tvalid_1's binary_logloss: 0.130261\n",
      "[200]\ttraining's binary_logloss: 0.106951\tvalid_1's binary_logloss: 0.110893\n",
      "[300]\ttraining's binary_logloss: 0.0926596\tvalid_1's binary_logloss: 0.0983428\n",
      "[400]\ttraining's binary_logloss: 0.0817966\tvalid_1's binary_logloss: 0.0888864\n",
      "[500]\ttraining's binary_logloss: 0.0729585\tvalid_1's binary_logloss: 0.0813172\n",
      "[600]\ttraining's binary_logloss: 0.0656031\tvalid_1's binary_logloss: 0.0751357\n",
      "[700]\ttraining's binary_logloss: 0.0593084\tvalid_1's binary_logloss: 0.0697267\n",
      "[800]\ttraining's binary_logloss: 0.0540336\tvalid_1's binary_logloss: 0.0653131\n",
      "[900]\ttraining's binary_logloss: 0.0493961\tvalid_1's binary_logloss: 0.0614758\n",
      "[1000]\ttraining's binary_logloss: 0.0451774\tvalid_1's binary_logloss: 0.0579182\n",
      "Fold 3 Optimal Threshold: 0.4000\n",
      "Fold 3 F1 Score: 0.94024\n",
      "\n",
      "======= Fold 4/5 =======\n",
      "[100]\ttraining's binary_logloss: 0.127516\tvalid_1's binary_logloss: 0.130579\n",
      "[200]\ttraining's binary_logloss: 0.106261\tvalid_1's binary_logloss: 0.11119\n",
      "[300]\ttraining's binary_logloss: 0.0922085\tvalid_1's binary_logloss: 0.0987143\n",
      "[400]\ttraining's binary_logloss: 0.0822502\tvalid_1's binary_logloss: 0.0900861\n",
      "[500]\ttraining's binary_logloss: 0.0733583\tvalid_1's binary_logloss: 0.0824697\n",
      "[600]\ttraining's binary_logloss: 0.0659223\tvalid_1's binary_logloss: 0.0760724\n",
      "[700]\ttraining's binary_logloss: 0.0595105\tvalid_1's binary_logloss: 0.0703838\n",
      "[800]\ttraining's binary_logloss: 0.053964\tvalid_1's binary_logloss: 0.0655113\n",
      "[900]\ttraining's binary_logloss: 0.0490747\tvalid_1's binary_logloss: 0.0613772\n",
      "[1000]\ttraining's binary_logloss: 0.0451647\tvalid_1's binary_logloss: 0.0581424\n",
      "Fold 4 Optimal Threshold: 0.4000\n",
      "Fold 4 F1 Score: 0.93881\n",
      "\n",
      "======= Fold 5/5 =======\n",
      "[100]\ttraining's binary_logloss: 0.128243\tvalid_1's binary_logloss: 0.130463\n",
      "[200]\ttraining's binary_logloss: 0.106737\tvalid_1's binary_logloss: 0.110941\n",
      "[300]\ttraining's binary_logloss: 0.0924856\tvalid_1's binary_logloss: 0.0982964\n",
      "[400]\ttraining's binary_logloss: 0.081148\tvalid_1's binary_logloss: 0.0882671\n",
      "[500]\ttraining's binary_logloss: 0.0726487\tvalid_1's binary_logloss: 0.0811042\n",
      "[600]\ttraining's binary_logloss: 0.0655099\tvalid_1's binary_logloss: 0.0749954\n",
      "[700]\ttraining's binary_logloss: 0.0592901\tvalid_1's binary_logloss: 0.0695464\n",
      "[800]\ttraining's binary_logloss: 0.0539462\tvalid_1's binary_logloss: 0.0649873\n",
      "[900]\ttraining's binary_logloss: 0.0490569\tvalid_1's binary_logloss: 0.0608456\n",
      "[1000]\ttraining's binary_logloss: 0.0448364\tvalid_1's binary_logloss: 0.0572688\n",
      "Fold 5 Optimal Threshold: 0.4000\n",
      "Fold 5 F1 Score: 0.94081\n",
      "CPU times: user 1h 8min 17s, sys: 4.65 s, total: 1h 8min 21s\n",
      "Wall time: 8min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 8. 使用最优参数进行最终模型训练\n",
    "print(\"\\n开始使用最优参数进行最终模型训练...\")\n",
    "\n",
    "# 五折交叉验证，使用五折构建特征时的切分规则，保证切分一致\n",
    "n_folds = 5\n",
    "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_thresholds = []\n",
    "fold_f1_scores = []\n",
    "models = []\n",
    "oof_preds = np.zeros(len(X_train))\n",
    "oof_probas = np.zeros(len(X_train))\n",
    "\n",
    "print(f\"\\n使用最优参数: {optimal_params}\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
    "    print(f\"\\n======= Fold {fold+1}/{n_folds} =======\")\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_set = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_set = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # 模型训练（使用最优参数）\n",
    "    model = lgb.train(\n",
    "        optimal_params, train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[train_set, val_set],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "            lgb.log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "    models.append(model)\n",
    "    \n",
    "    # 验证集预测\n",
    "    val_pred_proba = model.predict(X_val)\n",
    "    oof_probas[val_idx] = val_pred_proba\n",
    "    \n",
    "    # 阈值优化\n",
    "    best_threshold, best_f1 = find_optimal_threshold(y_val, val_pred_proba)\n",
    "    fold_thresholds.append(best_threshold)\n",
    "    \n",
    "    # 使用优化阈值计算F1\n",
    "    val_pred_labels = (val_pred_proba >= best_threshold).astype(int)\n",
    "    fold_f1 = f1_score(y_val, val_pred_labels)\n",
    "    fold_f1_scores.append(fold_f1)\n",
    "    oof_preds[val_idx] = val_pred_labels\n",
    "    \n",
    "    print(f\"Fold {fold+1} Optimal Threshold: {best_threshold:.4f}\")\n",
    "    print(f\"Fold {fold+1} F1 Score: {fold_f1:.5f}\")\n",
    "    \n",
    "    # 测试集预测\n",
    "    test_preds += model.predict(X_test) / n_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ec864a-519c-477b-93a6-0c5649d9d655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T19:43:44.981251Z",
     "iopub.status.busy": "2025-07-17T19:43:44.981001Z",
     "iopub.status.idle": "2025-07-17T19:43:46.426114Z",
     "shell.execute_reply": "2025-07-17T19:43:46.425644Z",
     "shell.execute_reply.started": "2025-07-17T19:43:44.981233Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 优化后的最终结果 =====\n",
      "使用的最优参数: {'objective': 'binary', 'metric': 'binary_logloss', 'verbose': -1, 'n_jobs': 8, 'seed': 42, 'max_depth': 15, 'num_leaves': 255, 'learning_rate': 0.1, 'min_child_samples': 10, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'bagging_freq': 3}\n",
      "Average Optimal Threshold: 0.4000\n",
      "Fold F1 Scores: ['0.93985', '0.93913', '0.94024', '0.93881', '0.94081']\n",
      "Average Fold F1: 0.93977\n",
      "OOF F1 Score: 0.93977\n",
      "\n",
      "Optimized submission file saved: submit_optimized.csv\n",
      "Predicted new user ratio: 0.1597\n",
      "Test set size: 1143309\n",
      "\n",
      "===== 优化后模型的特征重要性 =====\n",
      "                    Feature    Importance\n",
      "21  action_timespan_seconds  2.931054e+06\n",
      "19          first_action_ts  1.426011e+06\n",
      "15                common_ts  1.253119e+06\n",
      "17                frequency  5.197655e+05\n",
      "8                    appver  3.937382e+05\n",
      "18              mid_nunique  3.733504e+05\n",
      "7               common_city  3.031883e+05\n",
      "20           last_action_ts  2.608818e+05\n",
      "0                       mid  2.323566e+05\n",
      "14                      day  2.182267e+05\n",
      "6           common_province  2.159518e+05\n",
      "9                   channel  2.094014e+05\n",
      "12                     hour  2.017318e+05\n",
      "10                  os_type  1.350979e+05\n",
      "2              device_brand  1.294454e+05\n"
     ]
    }
   ],
   "source": [
    "# 9. 整体结果评估\n",
    "# 使用交叉验证平均阈值\n",
    "avg_threshold = np.mean(fold_thresholds)\n",
    "final_oof_preds = (oof_probas >= avg_threshold).astype(int)\n",
    "final_f1 = f1_score(y_train, final_oof_preds)\n",
    "\n",
    "print(\"\\n===== 优化后的最终结果 =====\")\n",
    "print(f\"使用的最优参数: {optimal_params}\")\n",
    "print(f\"Average Optimal Threshold: {avg_threshold:.4f}\")\n",
    "print(f\"Fold F1 Scores: {[f'{s:.5f}' for s in fold_f1_scores]}\")\n",
    "print(f\"Average Fold F1: {np.mean(fold_f1_scores):.5f}\")\n",
    "print(f\"OOF F1 Score: {final_f1:.5f}\")\n",
    "\n",
    "# 10. 测试集预测与提交文件生成\n",
    "# 使用平均阈值进行预测\n",
    "test_pred_labels = (test_preds >= avg_threshold).astype(int)\n",
    "submit['is_new_did'] = test_pred_labels\n",
    "\n",
    "# 保存提交文件\n",
    "submit[['is_new_did']].to_csv('submit_optimized.csv', index=False)\n",
    "print(\"\\nOptimized submission file saved: submit_optimized.csv\")\n",
    "print(f\"Predicted new user ratio: {test_pred_labels.mean():.4f}\")\n",
    "print(f\"Test set size: {len(test_pred_labels)}\")\n",
    "\n",
    "# 11. 特征重要性分析（使用优化后的模型）\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': models[0].feature_importance(importance_type='gain')\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n===== 优化后模型的特征重要性 =====\")\n",
    "print(feature_importance.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b805313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T19:43:46.426986Z",
     "iopub.status.busy": "2025-07-17T19:43:46.426726Z",
     "iopub.status.idle": "2025-07-17T19:43:46.431464Z",
     "shell.execute_reply": "2025-07-17T19:43:46.431072Z",
     "shell.execute_reply.started": "2025-07-17T19:43:46.426973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 网格搜索优化总结 =====\n",
      "原始参数组合 vs 优化后参数组合对比:\n",
      "原始参数:\n",
      "- max_depth: 12\n",
      "- num_leaves: 63\n",
      "- learning_rate: 0.1\n",
      "- feature_fraction: 0.7\n",
      "- bagging_fraction: 0.8\n",
      "- min_child_samples: 10\n",
      "\n",
      "优化后参数:\n",
      "- max_depth: 15\n",
      "- num_leaves: 255\n",
      "- learning_rate: 0.1\n",
      "- min_child_samples: 10\n",
      "- feature_fraction: 0.9\n",
      "- bagging_fraction: 0.8\n",
      "- bagging_freq: 3\n",
      "\n",
      "网格搜索说明:\n",
      "1. 第一阶段: 搜索核心结构参数 (max_depth, num_leaves, learning_rate, min_child_samples)\n",
      "2. 第二阶段: 基于最佳结构参数，搜索正则化参数 (feature_fraction, bagging_fraction, bagging_freq)\n",
      "3. 使用3折交叉验证评估每个参数组合，减少计算时间\n",
      "4. 最终使用最优参数组合进行5折交叉验证得到最终结果\n",
      "\n",
      "性能提升分析:\n",
      "通过网格搜索找到的最优参数组合可能会带来:\n",
      "- 更好的模型泛化能力\n",
      "- 减少过拟合风险\n",
      "- 提高F1分数\n",
      "- 更稳定的预测结果\n"
     ]
    }
   ],
   "source": [
    "# 12. 网格搜索结果总结与建议\n",
    "print(\"\\n===== 网格搜索优化总结 =====\")\n",
    "print(f\"原始参数组合 vs 优化后参数组合对比:\")\n",
    "print(\"原始参数:\")\n",
    "print(\"- max_depth: 12\")\n",
    "print(\"- num_leaves: 63\") \n",
    "print(\"- learning_rate: 0.1\")\n",
    "print(\"- feature_fraction: 0.7\")\n",
    "print(\"- bagging_fraction: 0.8\")\n",
    "print(\"- min_child_samples: 10\")\n",
    "\n",
    "print(f\"\\n优化后参数:\")\n",
    "for key, value in optimal_params.items():\n",
    "    if key not in ['objective', 'metric', 'verbose', 'n_jobs', 'seed']:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "print(f\"\\n网格搜索说明:\")\n",
    "print(\"1. 第一阶段: 搜索核心结构参数 (max_depth, num_leaves, learning_rate, min_child_samples)\")\n",
    "print(\"2. 第二阶段: 基于最佳结构参数，搜索正则化参数 (feature_fraction, bagging_fraction, bagging_freq)\")\n",
    "print(\"3. 使用3折交叉验证评估每个参数组合，减少计算时间\")\n",
    "print(\"4. 最终使用最优参数组合进行5折交叉验证得到最终结果\")\n",
    "\n",
    "print(f\"\\n性能提升分析:\")\n",
    "print(\"通过网格搜索找到的最优参数组合可能会带来:\")\n",
    "print(\"- 更好的模型泛化能力\")\n",
    "print(\"- 减少过拟合风险\") \n",
    "print(\"- 提高F1分数\")\n",
    "print(\"- 更稳定的预测结果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad743174",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-07-17T19:58:25.277999Z",
     "iopub.status.busy": "2025-07-17T19:58:25.277437Z",
     "iopub.status.idle": "2025-07-17T19:58:29.463460Z",
     "shell.execute_reply": "2025-07-17T19:58:29.462932Z",
     "shell.execute_reply.started": "2025-07-17T19:58:25.277977Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/site-packages (0.10.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/site-packages (from scikit-optimize) (1.4.2)\n",
      "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/site-packages (from scikit-optimize) (25.7.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-optimize) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/site-packages (from scikit-optimize) (1.7.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/site-packages (from scikit-optimize) (24.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "贝叶斯优化代码已准备好，取消注释即可使用\n",
      "贝叶斯优化相比网格搜索的优势:\n",
      "1. 更高效：基于先验知识智能选择下一个搜索点\n",
      "2. 更适合连续参数：可以搜索实数空间\n",
      "3. 收敛更快：通常用更少的评估次数找到更好的参数\n",
      "4. 适合高维搜索：当参数维度较高时表现更好\n"
     ]
    }
   ],
   "source": [
    "# 可选：贝叶斯优化方法（需要安装 scikit-optimize）\n",
    "# 取消注释下面的代码块来使用贝叶斯优化替代网格搜索\n",
    "\n",
    "\"\"\"\n",
    "# 安装依赖包\n",
    "!pip install scikit-optimize\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "def bayesian_optimization_lgb(X_train, y_train, n_calls=50):\n",
    "    '''贝叶斯优化LightGBM参数'''\n",
    "    print(\"开始贝叶斯优化参数搜索...\")\n",
    "    \n",
    "    # 定义搜索空间\n",
    "    search_space = [\n",
    "        Integer(6, 16, name='max_depth'),\n",
    "        Integer(15, 511, name='num_leaves'),\n",
    "        Real(0.01, 0.3, name='learning_rate'),\n",
    "        Real(0.5, 1.0, name='feature_fraction'),\n",
    "        Real(0.5, 1.0, name='bagging_fraction'),\n",
    "        Integer(3, 10, name='bagging_freq'),\n",
    "        Integer(5, 50, name='min_child_samples')\n",
    "    ]\n",
    "    \n",
    "    # 基础参数\n",
    "    base_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss', \n",
    "        'verbose': -1,\n",
    "        'n_jobs': 8,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    @use_named_args(search_space)\n",
    "    def objective(**params):\n",
    "        # 确保 num_leaves < 2^max_depth\n",
    "        if params['num_leaves'] >= 2**params['max_depth']:\n",
    "            return 1.0  # 返回一个差的分数\n",
    "        \n",
    "        # 合并参数\n",
    "        lgb_params = base_params.copy()\n",
    "        lgb_params.update(params)\n",
    "        \n",
    "        try:\n",
    "            # 评估参数\n",
    "            score = evaluate_params(lgb_params, X_train, y_train, n_folds=3)\n",
    "            # 贝叶斯优化是最小化，所以返回负的F1分数\n",
    "            return -score\n",
    "        except:\n",
    "            return 1.0  # 如果出错，返回差的分数\n",
    "    \n",
    "    # 执行贝叶斯优化\n",
    "    result = gp_minimize(func=objective,\n",
    "                        dimensions=search_space,\n",
    "                        n_calls=n_calls,\n",
    "                        random_state=42,\n",
    "                        verbose=True)\n",
    "    \n",
    "    # 提取最优参数\n",
    "    best_params = base_params.copy()\n",
    "    param_names = ['max_depth', 'num_leaves', 'learning_rate', \n",
    "                   'feature_fraction', 'bagging_fraction', 'bagging_freq', 'min_child_samples']\n",
    "    \n",
    "    for i, param_name in enumerate(param_names):\n",
    "        best_params[param_name] = result.x[i]\n",
    "    \n",
    "    print(f\"贝叶斯优化最佳F1分数: {-result.fun:.5f}\")\n",
    "    print(f\"贝叶斯优化最佳参数: {best_params}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# 使用贝叶斯优化（取消注释下面这行来启用）\n",
    "# optimal_params_bayes = bayesian_optimization_lgb(X_train, y_train, n_calls=50)\n",
    "\n",
    "\n",
    "print(\"贝叶斯优化代码已准备好，取消注释即可使用\")\n",
    "print(\"贝叶斯优化相比网格搜索的优势:\")\n",
    "print(\"1. 更高效：基于先验知识智能选择下一个搜索点\")\n",
    "print(\"2. 更适合连续参数：可以搜索实数空间\")\n",
    "print(\"3. 收敛更快：通常用更少的评估次数找到更好的参数\")\n",
    "print(\"4. 适合高维搜索：当参数维度较高时表现更好\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40440d35",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# LightGBM参数优化完整指南\n",
    "\n",
    "## 🎯 优化策略总览\n",
    "\n",
    "本notebook实现了两种参数优化方法：\n",
    "\n",
    "### 1. **网格搜索 (Grid Search)** - 当前使用的方法\n",
    "- **适用场景**: 参数空间较小，需要全面探索\n",
    "- **优势**: 保证找到搜索范围内的最优组合\n",
    "- **时间复杂度**: O(n^k) - n为每个参数的候选值数，k为参数个数\n",
    "- **实现**: 分两阶段搜索，先结构参数后正则化参数\n",
    "\n",
    "### 2. **贝叶斯优化 (Bayesian Optimization)** - 可选高级方法\n",
    "- **适用场景**: 参数空间较大，计算资源有限\n",
    "- **优势**: 智能搜索，快速收敛到最优解\n",
    "- **时间复杂度**: 更高效，通常50-100次评估即可\n",
    "- **实现**: 使用高斯过程建模，主动学习下一个搜索点\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 参数重要性排序\n",
    "\n",
    "### 核心结构参数 (影响最大)\n",
    "1. **max_depth** & **num_leaves**: 控制模型复杂度，防止过拟合\n",
    "2. **learning_rate**: 控制训练速度和最终性能的平衡\n",
    "3. **min_child_samples**: 叶子节点最小样本数，影响泛化能力\n",
    "\n",
    "### 正则化参数 (精细调节)\n",
    "4. **feature_fraction**: 特征采样比例，防止过拟合\n",
    "5. **bagging_fraction** & **bagging_freq**: 样本采样，提高鲁棒性\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 使用建议\n",
    "\n",
    "### 快速开始 (时间充裕)\n",
    "```python\n",
    "# 运行完整网格搜索 (推荐)\n",
    "optimal_params = grid_search_lgb(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 高效优化 (时间有限)\n",
    "```python\n",
    "# 1. 取消注释贝叶斯优化代码\n",
    "# 2. 安装依赖: !pip install scikit-optimize\n",
    "# 3. 运行贝叶斯优化\n",
    "optimal_params_bayes = bayesian_optimization_lgb(X_train, y_train, n_calls=50)\n",
    "```\n",
    "\n",
    "### 手动调参策略\n",
    "1. **先调结构参数**: max_depth, num_leaves\n",
    "2. **再调学习率**: learning_rate\n",
    "3. **最后调正则化**: feature_fraction, bagging_fraction\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡ 性能优化技巧\n",
    "\n",
    "1. **并行计算**: 设置 `n_jobs=8` 充分利用CPU\n",
    "2. **早停机制**: 使用 `early_stopping` 避免过训练\n",
    "3. **分阶段搜索**: 先粗调后精调，提高效率\n",
    "4. **交叉验证**: 使用3折快速评估，5折最终验证\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 预期效果\n",
    "\n",
    "通过参数优化，预期可以获得：\n",
    "- **F1分数提升**: 0.5% - 2%\n",
    "- **稳定性提升**: 减少方差，提高可靠性\n",
    "- **泛化能力**: 更好的测试集表现\n",
    "- **计算效率**: 找到速度和精度的最佳平衡点\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
